{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "### Goal of this series\n",
    "In this series, we will learn how to build a neural network from scratch. We will use python ans its libraries to build the network. I plan to explain a bit of the math, but I will not go into too much details. There also will be a code and some theory. This presentation is created as we go. Each chapter meeting I will create a new one. Everything will be available in git.\n",
    "\n",
    "### Prerequisites\n",
    "* You will need python. I will use python 3.10.\n",
    "* You can use Jupiter notebook (anaconda, intellij) as I do, or copy the cody into your IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __[Higher Level Overview](#Higher-Level-Overview)__\n",
    "    - __[What is Neural Network](#What-is-Neural-Network)__\n",
    "    - __[Structure and forward pass](#Structure-and-forward-pass)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher Level Overview\n",
    "In the first lecture I want to go over what a Neural Network is. I will introduce some terminology explain in basic terms how it works and create a neural network handwritten numbers detector using torch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Neural Network\n",
    "A Neural Network is a type of machine learning model inspired by the structure and function of the human brain. It is a multi-layered network of artificial \"neurons,\" each of which performs a simple calculation on the input data and passes it on to the next layer.\n",
    "\n",
    "Each neuron in a layer takes in a weighted sum of its inputs, applies an activation function to the result, and outputs the result as its own activation.\n",
    "\n",
    "The weights of the connections between the neurons are adjusted during the training process using algorithms such as backpropagation. The goal of this training is to find the optimal values for the weights such that the network accurately predicts the target outputs for a given set of inputs.\n",
    "\n",
    "Neural networks are used for a wide range of applications, including image and speech recognition, natural language processing, and game playing. They are particularly well-suited for problems where there is a lot of complex, non-linear data, and where a traditional, rule-based approach would be too cumbersome to develop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure and forward pass\n",
    "A forward pass, also known as a forward propagation, is a key operation in the evaluation of a neural network. It refers to the process of computing the outputs of a neural network, given a set of inputs and the current values of the weights and biases.\n",
    "\n",
    "The forward pass starts with the input layer and propagates the inputs forward through the network, layer by layer, until it reaches the output layer. At each neuron, the weighted sum of its inputs is computed and passed through an activation function to produce an output, which is then passed on to the next layer as input. The outputs of the final layer are the predictions of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how do we calculate this forward pass? To make things simple lets focus on just one neuron. Each neuron has an input and bias associated to the neuron. And each neuron in one layer is connected to all neurons in the next layer. This connection is represented by a weight associated to the connection. The output of the neuron is calculated as follows:\n",
    "\\begin{equation}\n",
    "    \\hat{y} = w * x + b\n",
    "\\end{equation}\n",
    "Where $w$ is the weight, $x$ is the input and $b$ is the bias.\n",
    "But considering that we usually have multiple neurons connected. We need to calculate something called weighted sum. This is the sum of all the outputs of the neurons in the previous layer. This is calculated as follows:\n",
    "\\begin{equation}\n",
    "    \\hat{y} = (w_1 * x_1 + w_2 * x_2 + ... + w_n * x_n) + b\n",
    "\\end{equation}\n",
    "But as you can see this will quickly become tedious. So to simplify this we can use vectors and linear algebra to calculate the sum. This would be denoted like this:\n",
    "\\begin{equation}\n",
    "    \\hat{y} = b + \\sum_{i=1}^{n} w_i * x_i\n",
    "\\end{equation}\n",
    "Where $x$ is the vector of inputs: $x = [x_1, x_2, ..., x_n]$, $w$ is the vector of weights: $w = [w_1, w_2, ..., w_n]$ and $b$ is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "### Goal of this series\n",
    "In this series, we will learn how to build a neural network from scratch. We will use python ans its libraries to build the network. I plan to explain a bit of the math, but I will not go into too much details. There also will be a code and some theory. This presentation is created as we go. Each chapter meeting I will create a new one. Everything will be available in git.\n",
    "\n",
    "### Prerequisites\n",
    "* You will need python. I will use python 3.10.\n",
    "* You can use Jupiter notebook (anaconda, intellij) as I do, or copy the cody into your IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __[First Lecture](#First-Lecture)__\n",
    "    - __[What is Neural Network](#What-is-Neural-Network)__\n",
    "    - __[Single Neuron](#Single-Neuron)__\n",
    "    - __[Activation Function](#Activation-Function)__\n",
    "    - __[Forward Propagation](#Forward-Propagation)__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Lecture\n",
    "In the first lecture I will explain what a neural network is and how it works in basic terms. I will introduce some terminology and we will show how to calculate single neuron and we put it together to achieve forward propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Neural Network\n",
    "A Neural Network is a type of machine learning model inspired by the structure and function of the human brain. It is a multi-layered network of artificial \"neurons,\" each of which performs a simple calculation on the input data and passes it on to the next layer.\n",
    "\n",
    "Each neuron in a layer takes in a weighted sum of its inputs, applies an activation function to the result, and outputs the result as its own activation.\n",
    "\n",
    "The weights of the connections between the neurons are adjusted during the training process using algorithms such as backpropagation. The goal of this training is to find the optimal values for the weights such that the network accurately predicts the target outputs for a given set of inputs.\n",
    "\n",
    "Neural networks are used for a wide range of applications, including image and speech recognition, natural language processing, and game playing. They are particularly well-suited for problems where there is a lot of complex, non-linear data, and where a traditional, rule-based approach would be too cumbersome to develop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Neuron\n",
    "A forward pass, also known as a forward propagation, is a key operation in the evaluation of a neural network. It refers to the process of computing the outputs of a neural network, given a set of inputs and the current values of the weights and biases.\n",
    "\n",
    "The forward pass starts with the input layer and propagates the inputs forward through the network, layer by layer, until it reaches the output layer. At each neuron, the weighted sum of its inputs is computed and passed through an activation function to produce an output, which is then passed on to the next layer as input. The outputs of the final layer are the predictions of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how do we calculate this forward pass? To make things simple lets focus on just one neuron. Each neuron has an input and bias associated to the neuron. And each neuron in one layer is connected to all neurons in the next layer. This connection is represented by a weight associated to the connection. The output of the neuron is calculated as follows:\n",
    "\\begin{equation}\n",
    "    \\hat{y} = wx + b\n",
    "\\end{equation}\n",
    "Where $w$ is the weight, $x$ is the input and $b$ is the bias.\n",
    "But considering that we usually have multiple neurons connected. We need to calculate something called weighted sum. This is the sum of all the outputs of the neurons in the previous layer. This is calculated as follows:\n",
    "\\begin{equation}\n",
    "    \\hat{y} = (w_1 * x_1 + w_2 * x_2 + ... + w_n * x_n) + b\n",
    "\\end{equation}\n",
    "But as you can see this will quickly become tedious. So to simplify this we can use vectors and linear algebra to calculate the sum. This would be denoted like this: (note that instead of using the sum we are using a dot product of two vectors which achieves the same result)\n",
    "\\begin{equation}\n",
    "    \\hat{y} = b + \\textbf{y} \\cdot \\textbf{x}\n",
    "\\end{equation}\n",
    "Where $x$ is the vector of inputs: $x = [x_1, x_2, ..., x_n]$, $w$ is the vector of weights: $w = [w_1, w_2, ..., w_n]$ and $b$ is the same.\n",
    "\n",
    "Now lets see some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first neuron output yay!:  4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # NumPy is the fundamental package for linear algebra and multidimensional arrays.\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "output = np.dot(weights, inputs) + bias # Using numpy the weighted sum is very simple. Using the dot product we get exactly what we want.\n",
    "\n",
    "print('Our first neuron output yay!: ', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "On key part of the neuron that I skipped over is the activation function. This is a function that is applied to the output of the neuron. This function is used to introduce non-linearity into the network. This is important because without it the network would be just a linear function. This would be very limiting. Now what does that actually mean? Let's look at some [graphs](https://www.desmos.com/calculator/con0g5kv6z). In this graph we are using something called ReLu function or Rectified Linear Unit. This function is defined as follows:\n",
    "\\begin{equation}\n",
    "    f(x) = max(0, x)\n",
    "\\end{equation}\n",
    "This function is very simple. It takes the input and returns it if it is positive. If it is negative it returns 0. This function is very simple and easy to calculate. But it is also very powerful. It is used in many neural networks. It is also very easy to calculate. This is why it is used so much.\n",
    "\n",
    "In the graph we can clearly see the difference between linear function and non-linear function like ReLu. You can go to folder \"W and B Linear\" and  \"W and b Relu\" to play with values of biases and weights. The goal is to fine tune the values to fit the displayed data as perfectly as possible. If you play with the nobs for a minute. You can clearly see that the linear function is very limited in how it can fit the data. But the ReLu function can fit the data very well. This is because it is non-linear. This is why it is so important to use non-linear functions in neural networks.\n",
    "\n",
    "Some other activation functions are:\n",
    "* Sigmoid\n",
    "* Tanh\n",
    "* Softmax\n",
    "* Leaky ReLu\n",
    "\n",
    "So if we now want to adjust our neuron to use the ReLu function we can do it like this:\n",
    "\\begin{equation}\n",
    "    g(x) = max(0, x)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\hat{y} = g(b + \\textbf{w} \\cdot \\textbf{x})\n",
    "\\end{equation}\n",
    "Now we have fully calculated a single neuron. This is the basic building block of neural networks. We can now use this to do something called forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first neuron output yay!:  4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # NumPy is the fundamental package for linear algebra and multidimensional arrays.\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "g = lambda x: max(0, x) # This is the ReLu function. We can use lambda to define it.\n",
    "\n",
    "output = g(np.dot(weights, inputs) + bias) # Using numpy the weighted sum is very simple. Using the dot product we get exactly what we want.\n",
    "\n",
    "print('Our first neuron output yay!: ', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation\n",
    "So how do we put it together? Putting it together isn't as hard as it may seem. We have seen how we can use vectors to simplify some calculations. Now we will step it up a notch and use matrices. This will allow us to calculate the output of multiple neurons at once. This is very important because we usually have multiple neurons in a layer. This is how we can calculate the output of a layer:\n",
    "\\begin{equation}\n",
    "    y = g(\\textbf{b} + \\textbf{W} \\cdot \\textbf{X})\n",
    "\\end{equation}\n",
    "\n",
    "Looks very similar right? But now we use matrices for inputs and weights and vector for biases.\n",
    "\\begin{document}\n",
    "\\[\n",
    "X = \\begin{bmatrix}\n",
    "    x_{11} & \\dots  & x_{1j}\\\\\n",
    "    \\vdots & \\ddots & \\vdots\\\\\n",
    "    x_{n1} & \\dots  & x_{nj}\n",
    "    \\end{bmatrix}\n",
    "\\qquad\n",
    "W = \\begin{bmatrix}\n",
    "    w_{11} & \\dots  & w_{1j}\\\\\n",
    "    \\vdots & \\ddots & \\vdots\\\\\n",
    "    w_{n1} & \\dots  & w_{nj}\n",
    "    \\end{bmatrix}\n",
    "\\]\n",
    "\\qquad\n",
    "b = \\begin{bmatrix}\n",
    "    b_1\\\\\n",
    "    \\vdots\\\\\n",
    "    b_n\n",
    "    \\end{bmatrix}\n",
    "\\end{document}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03637784 -0.04531111]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Activation:\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, n_inputs: int, n_neurons: int):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def linear(self, inputs_x):\n",
    "        return np.dot(inputs_x, self.weights) + self.biases\n",
    "\n",
    "\n",
    "inputs_x = np.random.randn(1, 10)\n",
    "\n",
    "layer1 = Layer(10, 3)\n",
    "layer2 = Layer(3, 2)\n",
    "\n",
    "layer1Out = layer1.linear(inputs_x)\n",
    "layer2Out = layer2.linear(layer1Out)\n",
    "\n",
    "print(layer2Out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
